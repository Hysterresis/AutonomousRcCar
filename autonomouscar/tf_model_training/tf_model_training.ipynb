{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDUzt1XPfCwF",
        "colab_type": "text"
      },
      "source": [
        "# Enable GPU acceleration\n",
        "Go to: \n",
        "`Edit > Notebook settings > Hardware accelerator > GPU`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxaJ77k3BUnn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "dca661f0-75ed-4281-f55f-973533956eb0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "print(\"Libraries version:\")\n",
        "print(f\"Numpy:      {np.__version__}\")\n",
        "print(f\"Matplotlib: {matplotlib.__version__}\")\n",
        "print(f\"Tensorflow: {tf.__version__}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Libraries version:\n",
            "Numpy:      1.18.5\n",
            "Matplotlib: 3.2.2\n",
            "Tensorflow: 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsRC2uBuayLO",
        "colab_type": "text"
      },
      "source": [
        "# Get all files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAHqwvxec8X4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a9982e9-6cb2-44fe-aed9-d7d45e4b2b97"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFeoHunVeeaY",
        "colab_type": "text"
      },
      "source": [
        "## Load Git repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvzaTf9pBqoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5b46ab44-0015-4cae-b7ff-770f624e36c8"
      },
      "source": [
        "if not os.path.isdir(\"AutonomousRcCar\"):\n",
        "    !git clone https://github.com/maximecharriere/AutonomousRcCar.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AutonomousRcCar'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 1059 (delta 2), reused 11 (delta 2), pack-reused 1047\u001b[K\n",
            "Receiving objects: 100% (1059/1059), 554.52 MiB | 9.62 MiB/s, done.\n",
            "Resolving deltas: 100% (386/386), done.\n",
            "Checking out files: 100% (558/558), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjkzqN5ZB4aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_training_dir_path = \"/content/AutonomousRcCar/autonomouscar/tf_model_training\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCLmg4uccW1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "69f2732a-e81c-4062-8230-233f0b3f7ffa"
      },
      "source": [
        "if not os.path.isdir(\"models\"):\n",
        "    !git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 38032, done.\u001b[K\n",
            "remote: Total 38032 (delta 0), reused 0 (delta 0), pack-reused 38032\u001b[K\n",
            "Receiving objects: 100% (38032/38032), 544.52 MiB | 25.20 MiB/s, done.\n",
            "Resolving deltas: 100% (25503/25503), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkJRUGdIeRIC",
        "colab_type": "text"
      },
      "source": [
        "## Load pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBNntXPPXsH5",
        "colab_type": "text"
      },
      "source": [
        "Choose a tensorflow model:\n",
        "- [All object detection models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models)\n",
        "- [Models compatible with Coral Edge TPU](https://coral.ai/models/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3JBTk3Belj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03'\n",
        "\n",
        "if not os.path.isdir(model_name):\n",
        "    base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "    model_file = model_name + '.tar.gz'\n",
        "    urllib.request.urlretrieve(base_url + model_file, model_file)\n",
        "    with tarfile.open(model_file) as tar:\n",
        "        tar.extractall()\n",
        "    os.remove(model_file)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv2A4HA5u7ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(model_name, \"model.ckpt\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZIhxcJxbfTq",
        "colab_type": "text"
      },
      "source": [
        "# Install the Tensorflow Object Detection API\n",
        "It's necessary in the next scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-GJ70Yq8gxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "1191daab-a3ac-4841-a0ed-f7285b362e70"
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "!pip install -q tf_slim\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "\u001b[K     |████████████████████████████████| 358kB 7.4MB/s \n",
            "\u001b[?25h/content/models/research\n",
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n",
            "2020-07-02 14:53:48.086432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV7Fa-clwEK9",
        "colab_type": "text"
      },
      "source": [
        "# Generate `tfrecord` files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBNu4Vzufyri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fb82f9a-1233-4725-cb02-c89699d8cc26"
      },
      "source": [
        "%cd {model_training_dir_path}"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/AutonomousRcCar/autonomouscar/tf_model_training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap5t8m47gGmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Partition data between test and train set\n",
        "!python3 scripts/partition_dataset.py -i training/images/all -o training/images -r 0.2 -x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihBKBJYtXEAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9d2e446f-1383-4042-a283-38a53c7b9dc7"
      },
      "source": [
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "!python3 scripts/xml_to_csv.py -i training/images/train -o training/annotations/train_labels.csv -l training/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "!python3 scripts/xml_to_csv.py -i training/images/test -o training/annotations/test_labels.csv"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully converted xml to csv.\n",
            "Generate `training/annotations/label_map.pbtxt`\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db3Way4el05W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a9fb42d8-2458-47f8-f750-607d151d9cca"
      },
      "source": [
        "# Generate `train.record`\n",
        "!python scripts/generate_tfrecord.py --csv_input=training/annotations/train_labels.csv --output_path=training/annotations/train.record --img_path=training/images/train --label_map training/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python scripts/generate_tfrecord.py --csv_input=training/annotations/test_labels.csv --output_path=training/annotations/test.record --img_path=training/images/test --label_map training/annotations/label_map.pbtxt\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-02 14:55:28.227166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Successfully created the TFRecords: /content/AutonomousRcCar/autonomouscar/tf_model_training/training/annotations/train.record\n",
            "2020-07-02 14:55:32.690780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Successfully created the TFRecords: /content/AutonomousRcCar/autonomouscar/tf_model_training/training/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTeoGOvUxHc8",
        "colab_type": "text"
      },
      "source": [
        "# Configuring the Training `pipeline.conf`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeCZ-HyF_aHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIkQnXxF_1Gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 24\n",
        "num_steps = 1000\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "test_record_fname = model_training_dir_path + '/training/annotations/test.record'\n",
        "train_record_fname = model_training_dir_path + '/training/annotations/train.record'\n",
        "label_map_pbtxt_fname = model_training_dir_path + '/training/annotations/label_map.pbtxt'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwJiSOfNyvCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49e642ff-e9c0-45ad-e137-7e93bfb67783"
      },
      "source": [
        "%cd /content\n",
        "pipeline_fname = os.path.join(model_name, \"pipeline.config\")\n",
        "assert os.path.isfile(pipeline_fname), f'`{pipeline_fname}` not exist'"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyG2zZUJ_J-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               f'fine_tune_checkpoint: \"{fine_tune_checkpoint}\"', s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', f'input_path: \"{train_record_fname}\"', s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', f'input_path: \"{test_record_fname}\"', s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', f'label_map_path: \"{label_map_pbtxt_fname}\"', s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               f'batch_size: {batch_size}', s)\n",
        "    \n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               f'num_steps: {num_steps}', s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               f'num_classes: {num_classes}', s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}